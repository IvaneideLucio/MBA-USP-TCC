{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1rzH-HOYv52F",
   "metadata": {
    "editable": true,
    "id": "1rzH-HOYv52F",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "O que fazer nesse arquivo:\n",
    "V2: \n",
    "- retirada de Bag of Words, porque TfIdf é uma melhoria dele.\n",
    "- retirada dos grupos de menor expressividade nos dados.\n",
    "\n",
    "- Consistência e estabilidade: verificar a consistência dos resultados de agrupamentos em diferentes execuções ou subconjuntos de dados.\n",
    "- Análise de sensibilidade: Avaliar como pequenas alterações nos dados afetam os resultados do agrupamentos. Modelos robustos a pequenas mudanças são preferíveis\n",
    "- Interpetação e Relevância os domínio: considerar qual técnica faz mais sentidos para o domínio.\n",
    ">- obs: Word2Vec pode ser melhor para textos maiores e mais contextualizados, equanto  TF-IDF pode funcionar melhor para textos mennores e mais diretos\n",
    "- Pode ser necessário dividir os arquivos para não estourar a RAM google:\n",
    ">- exemplo: uma para visualização e limpeza, outros para aplicaddo de técnicas diferentes de tratamento e um outro para a junção das técnicas.\n",
    "- verificar se precisa de redução de dimensão\n",
    "- aplicar nomavente\n",
    "\n",
    "Porque fazer isso?\n",
    "- Aproveitar as vantagens os algoritmos redutores para melhorar a qualidade dos agrupamentos\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cf72e-6d09-4c3f-9e0d-295bb21cd2e1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ece8b6-9465-4f28-b505-639b32c1dcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import regex as re\n",
    "from sklearn.metrics import adjusted_rand_score, f1_score, precision_score, recall_score, homogeneity_completeness_v_measure\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722fd608-d73e-42ba-b5a5-913da3b82207",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aec460-572f-45ea-9831-56d2918a8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar a distribuição dos pontos \n",
    "def plot_(n_components,scaled,df_nome,y_l):\n",
    "    plt.scatter(scaled[:,0],scaled[:,1],c=y_l, cmap='viridis',s=2)\n",
    "    plt.title(f' {df_nome}')\n",
    "    plt.xlabel('Comp  1')\n",
    "    plt.ylabel('Comp  2' if n_components > 1 else '')\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25828e87-4156-4dfa-ae9a-4e6af5d53b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular as métricas \n",
    "\n",
    "metrica = []\n",
    "def coleta_metricas(y,labels,dataset_name):\n",
    "  ari_score = adjusted_rand_score(y, labels)\n",
    "  metricas.append([dataset_name,'ARI Score',ari_score])\n",
    "  #={'dataset':dataset, 'metrica':'ARI Score df','score':ari_score }\n",
    "  # Para V-measure\n",
    "  homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y, labels)\n",
    "  metricas.append([dataset_name,'homogeneity',homogeneity])\n",
    "  metricas.append([dataset_name,'completeness',completeness])\n",
    "  metricas.append([dataset_name, 'v_measure',v_measure])\n",
    "\n",
    "  # Para F1-Score, Precisão e Revocação  (adaptar para multiclasse)\n",
    "  precision = precision_score(y, labels, average='macro')\n",
    "  recall = recall_score(y, labels, average='macro')\n",
    "  f1_scr = f1_score(y, labels, average='macro')\n",
    "  metricas.append([dataset_name, 'precision',precision])\n",
    "  metricas.append([dataset_name,'recall',recall])\n",
    "  metricas.append([dataset_name, 'f1_score',f1_scr])\n",
    "\n",
    "  return metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1bef8e-5b5e-483f-b332-31289868b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gráfico\n",
    "def plot(sil_avg, best_k, df_name, marker='o'):\n",
    "  plt.scatter( sil_avg.iloc[:,0],sil_avg.iloc[:,1], marker=marker)\n",
    "  title = f'Melhor k: {df_name} - {best_k}' if isinstance(best_k, int) else f'dataset: {df}'\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Clusters (k)')\n",
    "  plt.ylabel('Escore')\n",
    "  plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d95b1c-2718-4cf8-ba48-193478c24e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "import pandas as pd\n",
    "\n",
    "# Calculando o comprimento de cada texto\n",
    "df['comprimento_texto'] = df['text'].apply(len)\n",
    "\n",
    "# Encontrando o comprimento do maior e do menor texto\n",
    "comprimento_maximo = df['comprimento_texto'].max()\n",
    "comprimento_minimo = df['comprimento_texto'].min()\n",
    "\n",
    "print(f'O comprimento do maior texto é: {comprimento_maximo}')\n",
    "print(f'O comprimento do menor texto é: {comprimento_minimo}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad45b6eb-b534-4572-8aec-ab528da2f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Coleta dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b281f22-474f-42c1-b365-21ce3f4c2f60",
   "metadata": {},
   "source": [
    "##### DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a03255-894f-4eab-bd94-f64698403d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea4e57-1793-4ebe-ac7b-582b72c7a64f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run open_df1_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392556f3-4136-407a-a026-c635ba6a2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpeza adicional do df1\n",
    "\n",
    "# extraindo partes do texto sem significado no texto, mas que podem impactar o agrupamento\n",
    "qtd = 0\n",
    "total_pre = df_1.shape[0]\n",
    "import regex as re\n",
    "qtd = qtd + df_1['text'].str.contains('confirmed their accuracy').sum() + df_1['text'].str.contains('\\(Reuters\\) - ').sum() + df_1['text'].str.contains('@realDonaldTrump: - ').sum()\n",
    "df_1['text'] = df_1['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)\n",
    "# df_1.loc[:, 'text'] = df_1['text'].str.replace(r'^.*\\(Reuters\\) - ', '', regex=True)\n",
    "df_1['text'] = df_1['text'].str.replace(r'@realDonaldTrump\\s*:\\s*-\\s*', '', regex=True, flags=re.IGNORECASE)\n",
    "# df_1.loc[:, 'text'] = df_1['text'].str.replace(r'@realDonaldTrump\\s*:\\s*-\\s*', '', regex=True, flags=re.IGNORECASE)\n",
    "df_1['text'] = df_1['text'].str.replace(r'^.*?confirmed their accuracy\\.', '', regex=True)\n",
    "print(f'{qtd} atualizados')\n",
    "\n",
    "# limpando ocorrências de texto vazias:\n",
    "df_1 = df_1[~(df_1['text'].str.strip() == '')]\n",
    "\n",
    "# extraindo duplicatas:\n",
    "# de todos os atributos\n",
    "qtd = qtd + df_1.duplicated().sum()\n",
    "print(f'shape antes da exclusão de duplicatas',df_1.shape)\n",
    "df_1.drop_duplicates(inplace=True)\n",
    "\n",
    "# de textos duplicados\n",
    "qtd = qtd+ df_1.duplicated(subset=['text']).sum()\n",
    "df_1.drop_duplicates(subset=['text'],inplace=True)\n",
    "print(f'shape após da exclusão de duplicatas',df_1.shape)\n",
    "total_pos = df_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab2bf1-3bb7-4df7-a70d-8f0d1fb755e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de correções entre limpeza e exclusões:{qtd}, que representa {round(qtd/total_pre*100,2)}% ocorrências com os problemas indicados' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08dd08-baa4-4ef8-b163-dff70973b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Análise da frequência da palavras\n",
    "# all_texts = ' '.join(df['txt_lmtzd'].tolist())\n",
    "\n",
    "# # Tokenização\n",
    "# tokens = nltk.word_tokenize(all_texts)\n",
    "\n",
    "# # Remoção de stop words (ajuste o idioma conforme necessário)\n",
    "# stop_words = set(stopwords.words('portuguese'))\n",
    "# tokens_without_sw = [word for word in tokens if not word in stop_words]\n",
    "# # Frequência de palavras\n",
    "# word_freq = Counter(tokens_without_sw)\n",
    "\n",
    "# # Exibindo as 10 palavras mais comuns\n",
    "# most_common_words = word_freq.most_common(200)\n",
    "\n",
    "# # print(\"As 150 palavras mais comuns e suas frequências:\")\n",
    "# # for word, freq in most_common_words:\n",
    "# #     print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23604631-df84-44c4-b794-24b7d3e45741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e0fc4-d6c1-4134-ae23-fca8f5cb066a",
   "metadata": {},
   "source": [
    "##### DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982eb9ad-8011-48a7-817f-13a46b44c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run open_df2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873cb32-4073-4303-9ca7-81e06fb08103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Excluindo duplicatas\n",
    "# print(f'Com duplicadas: {df_2.shape[0]}')\n",
    "# df_2.drop_duplicates(inplace=True)\n",
    "# df_2.drop_duplicates(subset=['text'], inplace=True)\n",
    "# print(f'Sem duplicadas: {df_2.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHGu_RnKU18p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1706216755755,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "nHGu_RnKU18p",
    "outputId": "8f1cd6d5-8238-4b74-f2b9-843f119959fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_1.copy()\n",
    "# df = df_2.copy()\n",
    "y_df = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea726f-006e-4936-aa23-1bab54ea0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6471-gEkak",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1706216755755,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "ca6471-gEkak",
    "outputId": "031c8cc8-3da1-413a-ed0e-d77fc6ac2a8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Porporção por alvo')\n",
    "# round(df.groupby(['target'])['text'].count()/df.shape[0]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9bfe4-57a5-46b9-af05-3e31b0f128bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronização do target\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['subject'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658906bb-112e-4f8e-adcb-b387bf6f3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique(), df['subject'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qEW5v2SZPvIY",
   "metadata": {
    "id": "qEW5v2SZPvIY"
   },
   "source": [
    "##### Data_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rGKV8eX8MaD4",
   "metadata": {
    "editable": true,
    "id": "rGKV8eX8MaD4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3zpZte7kP9Bl",
   "metadata": {
    "id": "3zpZte7kP9Bl"
   },
   "source": [
    "A limpeza e pré-processamento consistiu no seguinte:\n",
    "\n",
    "1. conversão para minúsculas\n",
    "2. remoção de caracteres não alfa\n",
    "3. remoção de palavras isoladas e espaços extras, remoção de números;\n",
    "4. remoção de stowords\n",
    "5. Lemtização e Stemming\n",
    "6. repetição dos passos 2 e 3 para remoção de ruídos resultantes do passo 5\n",
    "7. remoção de duplicatas\n",
    "8. remoção de frases referêntes ás fontes das informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5752afd-0a6e-4c7b-a2eb-fbc23b51544a",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706216759771,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "e5752afd-0a6e-4c7b-a2eb-fbc23b51544a"
   },
   "outputs": [],
   "source": [
    "# 2 - pré-processamento dos textos\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "from nltk import pos_tag\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65416c-c157-4d66-ae9d-37ecd8ffc893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1706216760200,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "8c65416c-c157-4d66-ae9d-37ecd8ffc893",
    "outputId": "fb5ca241-b241-4ad2-bf6f-aa636294f846",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Só precisa baixar uma vez, se for máquina local\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SKTbyMvcPFQY",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706216760200,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "SKTbyMvcPFQY"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b9c42-d32d-4586-94ea-d62398e898a0",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706216768387,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "490b9c42-d32d-4586-94ea-d62398e898a0"
   },
   "outputs": [],
   "source": [
    "# processo de lemmatização:\n",
    "# remoção de caracteres não alfa e conversão para minúsculas,\n",
    "# remoção de palavras isoladas e espaços extras, remoção de números;\n",
    "# remoção de stowords\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Removendo caracteres não alfabéticos e convertendo para minúsculas\n",
    "    text = re.sub(r'\\W', ' ', str(text))\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removendo palavras isoladas e espaços extras\n",
    "    text = re.sub(r'\\s+[a-z]\\s+', ' ', text)\n",
    "    text = re.sub(r'^[a-z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Removendo números (opcional)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Removendo quebra de linha manual\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\t', '', text)\n",
    "\n",
    "    # remoção de stopwords, gera os radicais conforme a funçõa da palavra no contexto\n",
    "    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS ])\n",
    "    \n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2829f-30be-4a8e-b5e2-1c3a47f36979",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706216768387,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "bee2829f-30be-4a8e-b5e2-1c3a47f36979",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#função para classificar a palavra conforme a função na frase\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Mapeia a tag POS do NLTK para a primeira caracter do lematizador do WordNet.\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883ff6d-64ae-45ae-9952-795c8966d47e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['txt_limpo'] = [preprocess(text) for text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0950c-2f1b-4f8e-8cc1-c4735593df29",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 55014,
     "status": "ok",
     "timestamp": 1706216824717,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "ec9cb358-b6d3-439b-9c72-41083838a844",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lematização, gera os radicias levando em consideração a função da palavra no texto\n",
    "df['txt_lmtzd'] = df['txt_limpo'].apply(lambda x: ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9ab2d-20e9-4369-b449-54df39d1177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicação de limpeza de residuos pós lematização\n",
    "df['lmtzd_limpo'] = [preprocess(text) for text in df['txt_lmtzd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6e4c2-735c-44fb-8c40-538b1ee6f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoção de espaços vazios\n",
    "#substitui espaços vazios por nan\n",
    "df['lmtzd_limpo'].replace('', np.nan, inplace=True)\n",
    "# remoção de nans\n",
    "df.dropna(subset=['lmtzd_limpo'],axis=0, inplace=True)\n",
    "\n",
    "# remoção de ocorrências de frase com 3 palavras ou menos\n",
    "df = df[df['lmtzd_limpo'].str.split().apply(len) >= 4]\n",
    "\n",
    "# remoção de duplicatas\n",
    "df.drop_duplicates(subset=['lmtzd_limpo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbed6b-47de-4c49-9931-76e8d111df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt = (df['lmtzd_limpo']==df['txt_lmtzd']).sum()\n",
    "print(f\"número de ocorrências que sofretam alteração {alt} - {df.shape[0]}\") # dos 37431 do df_1 apenas 3001 e dos 3302 do df_2, apenas 994, não tiveram ajustes no novo processo de limpeza. \n",
    "# Isso demonstra que numa sequência de passos do pré-processamento, alguns passos devem ser repetidos\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7435376-cde3-4d2f-b2da-80e0c809ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluindo colunas excedente usada no tratamento.\n",
    "df['txt_lmtzd'] = df['lmtzd_limpo']\n",
    "df.drop(['lmtzd_limpo'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a18a2-b29a-4556-8fa9-fea3a33903f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtendo rótulos individuais, após undersumpling\n",
    "y_df_all_names = df['subject']\n",
    "y_df = df['target']\n",
    "\n",
    "# Exibindo os rótulos convertidos\n",
    "df_labels, df_sizes = np.unique(y_df, return_counts=True)\n",
    "true_k_df = df_labels.shape[0]\n",
    "print(f\"{df.shape[0]} documentos - {true_k_df} categorias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba022e37-eeb9-430e-a032-c68f87e84763",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea4e16-69e6-44ed-a4ba-cc42375e4419",
   "metadata": {},
   "source": [
    "#### Fim da Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef406fc6-ae0f-4e68-8cfd-94cb76182419",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df['c_count'] = df['txt_lmtzd'].str.len()\n",
    "df['w_count'] = df['txt_lmtzd'].str.split().str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85761240-20ca-4edc-8cc5-109bf5dfb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "menor = len(df['txt_lmtzd'][df['w_count'].idxmin()].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d8f20b-f71e-44ce-b03e-28d37995e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # Evita truncamento de coluna\n",
    "pd.set_option('display.max_rows', 15)  # Ajusta o número máximo de linhas a serem exibidas\n",
    "\n",
    "# Exibindo as primeiras 15 ocorrências da coluna 'texto'\n",
    "# print(df['txt_lmtzd'].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EH1ISMyBFeMx",
   "metadata": {
    "editable": true,
    "id": "EH1ISMyBFeMx",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Visualização dos dados após o tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R1j4HVKK5ssE",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 2962,
     "status": "ok",
     "timestamp": 1706216835912,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "R1j4HVKK5ssE",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agregando todos os textos para visualização\n",
    "textos_df = \" \".join(texto for texto in df['txt_lmtzd'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c750432-0261-40d1-a2cb-762b1d7ede36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a nuvem de palavras\n",
    "# wordcloud_df = WordCloud(background_color='white').generate(textos_df)\n",
    "wordcloud_df = WordCloud(width=800, height=400, max_font_size=100, max_words=100, min_font_size=10,background_color='white').generate(textos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5F5O2I4D_BhN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1706216835913,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "5F5O2I4D_BhN",
    "outputId": "514793f9-f398-41e0-93c2-82cb5183fe4e",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizando a nuvem de palavras\n",
    "plt.imshow(wordcloud_df, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec946603-65ba-4b1c-b32d-fd4abedd4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_df.to_file(\"df1_tratados.png\")\n",
    "print(f'arquivo df1_tratados.png criado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fTmqe9MK89Qt",
   "metadata": {
    "id": "fTmqe9MK89Qt"
   },
   "source": [
    "#### Gerando os vetores - Vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8451d-29b6-4ce6-878b-4dbdde3c6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Criando Representação Vetorial de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f894d00-6122-48ce-84bf-f9bf7eb69e5b",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1706216825057,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "3f894d00-6122-48ce-84bf-f9bf7eb69e5b",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1.1 - TF-IDF\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', max_df=0.2, min_df=0.1 , ngram_range=(1,3))\n",
    " \n",
    "dfx_idf = tfidf_vec.fit_transform(df['txt_lmtzd'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232a83c-3d04-4a37-a732-8a74a6c318c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfx_idf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0exD9x6FDGDe",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 4264,
     "status": "ok",
     "timestamp": 1706216829723,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "0exD9x6FDGDe",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  1.3 Word to Vector -  W2V\n",
    "# Treinamento do modelo Word2Vec\n",
    "model_df = Word2Vec([text.split() for text in df['txt_lmtzd']], vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FCygICBVV-nq",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706216829723,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "FCygICBVV-nq",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Função para converter texto em um vetor médio de word embeddings\n",
    "\n",
    "def get_avg_word_vec(text, model):\n",
    "    words = text.split()\n",
    "    word_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "\n",
    "    if len(word_vecs) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    elif len(word_vecs) == 1:\n",
    "        return word_vecs[0]\n",
    "    else:\n",
    "        return np.mean(word_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jMZQDzlWDKIM",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1706216830836,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "jMZQDzlWDKIM",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aplicar a função em todos os textos\n",
    "\n",
    "dfx_w2v = pd.DataFrame([get_avg_word_vec(text,model_df) for text in df['txt_lmtzd']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169ecd9-304a-4cc2-8178-f74015d2d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7183b1c-07dd-4e8c-964a-a087c1b65b8b",
   "metadata": {},
   "source": [
    "#### Redução de dimensionalidade/ nornalização dos dados e Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b973fc-f78b-4c35-a3e1-b6962b63040f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 101336,
     "status": "ok",
     "timestamp": 1706218606202,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "6PL6y5XQiFRr",
    "outputId": "c6b218ad-7361-435b-9450-17d6c6eda197",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#somente para Google Colab\n",
    "#!pip install umap\n",
    "# !pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ee56e-d24f-4a14-83d5-8fbaf223dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Inicialize o objeto StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398626f-e72a-436f-ade6-f01136fbab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redução de dimensionaliade usando UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2148562-9617-4ebb-b931-c4a8d4cad3ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 101336,
     "status": "ok",
     "timestamp": 1706218606202,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "6PL6y5XQiFRr",
    "outputId": "c6b218ad-7361-435b-9450-17d6c6eda197",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "umap = umap.UMAP(random_state=42)\n",
    "\n",
    "umap_tfidf = umap.fit_transform(dfx_idf)\n",
    "umap_w2v = umap.fit_transform(dfx_w2v)\n",
    "\n",
    "# Padronize os vetores\n",
    "umap_tfidf_sc = scaler.fit_transform(umap_tfidf)\n",
    "umap_w2v_sc = scaler.fit_transform(umap_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21fe70-fd59-4d76-9c32-6a719d9af4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar imagens dos gráficos dos dados reduzidos com os targets\n",
    "# coloca na seção de resultado juntos com os dados após a aplicação do modelo.\n",
    "# fazer isso com os escolhidos para a aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d9a97-d794-4bf4-9df0-00a52f64dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a90b63-a55d-4b11-9d07-87f4ee443708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_(2,umap_tfidf,'UMAP-TF-IDF',y_df)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_(2,umap_w2v,'UMAP-Word2Vec',y_df)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_(2,umap_tfidf_sc,'UMAP-TF-IDF_Norm',y_df)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_(2,umap_w2v_sc,'UMAP-Word2Vec_Norm',y_df)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_distrib_dados_UMAP.png') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f1e5b-5669-474c-8137-f7ab06ad6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redução de dimensionalidade com SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41c43e-93ab-43c4-ada0-82ea03b30733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)  # Escolha um número de componentes\n",
    "svd_tfidf = svd.fit_transform(dfx_idf)\n",
    "svd_w2v =   svd.fit_transform(dfx_w2v)\n",
    "\n",
    "# Padronize os vetores\n",
    "svd_tfidf_sc = scaler.fit_transform(svd_tfidf)\n",
    "svd_w2v_sc = scaler.fit_transform(svd_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932f803-19b0-405c-9a61-ce590c32bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2,2,1)\n",
    "plot_(2,svd_tfidf,'SVD-TF-IDF',y_df)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plot_(2,svd_w2v,'SVD-Word2Vec',y_df)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plot_(2,svd_tfidf_sc,'SVD-TF-IDF_Norm',y_df)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plot_(2,svd_w2v_sc,'SVD-Word2Vec_Norm',y_df)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_distrib_dados_SVD.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4a8b2-b003-4de2-b276-60ee014cae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reducação com NMF no texto ao TFIDF (não será raelizado ocom W2V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f214c6-5090-45a6-a6a4-7c7466b43d05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=2, random_state=0)  # n_components é o número de tópicos\n",
    "nmf_tfidf = nmf.fit_transform(dfx_idf)\n",
    "\n",
    "# Padronize os vetores\n",
    "nmf_tfidf_sc = scaler.fit_transform(nmf_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0142b73-5291-4970-be98-fa58c8e0006b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2,2,1)\n",
    "plot_(2,nmf_tfidf,'NMF-TF-IDF',y_df)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plot_(2,nmf_tfidf_sc,'NMF-TF-IDF_norm',y_df)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_distrib_dados_NMF.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdd9b8-7c38-4c2d-88ff-9ec890ed971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reducação com tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba5f81-2681-4ea6-a9aa-3ae73b346f99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_tfidf = tsne.fit_transform(dfx_idf.toarray())\n",
    "tsne_w2v   = tsne.fit_transform(dfx_w2v)\n",
    "\n",
    "# Padronize os vetores\n",
    "tsne_tfidf_sc = scaler.fit_transform(tsne_tfidf)\n",
    "tsne_w2v_sc = scaler.fit_transform(tsne_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3d35a-fc92-4c54-bd03-9f9790bf59f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2,2,1)\n",
    "plot_(2,tsne_tfidf,'tSEN-TF-IDF',y_df)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plot_(2,tsne_w2v,'tSEN-Word2Vec',y_df)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plot_(2,tsne_tfidf_sc,'tSEN-TF-IDF_Norm',y_df)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plot_(2,tsne_w2v_sc,'tSEN-Word2Vec_Norm',y_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_distrib_dados_tsne.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H2kbsRFnFzW6",
   "metadata": {
    "editable": true,
    "id": "H2kbsRFnFzW6",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Modelo - Experimentação, treinamento, aplicação, validação e ajustes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zf8OVqF8P2PF",
   "metadata": {
    "id": "Zf8OVqF8P2PF"
   },
   "source": [
    "### 3. Experimentação - melhor valor de K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f6a03-29ff-4acb-8e39-9edc6ea272e6",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeecbb9-c1d6-48a3-a2d2-135c35ed99cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a4c492d-0035-44fb-96db-e4bf15935960",
   "metadata": {},
   "source": [
    "======================= INICIO DO TESTE =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b19ee8-9f59-40fe-b274-0da46e006e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a440a3f-c282-4069-95bf-955397845831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAzer assim que terminar a geração do vetor\n",
    "# Substituir pelas listas de vetores normalizados e fazer um for\n",
    "\n",
    "Xs = ['nmf_tfidf_sc','svd_tfidf_sc','tsne_tfidf_sc','umap_tfidf_sc','svd_w2v_sc','tsne_w2v_sc','umap_w2v_sc']\n",
    "\n",
    "\n",
    "# Variando os parâmetros do K-means\n",
    "n_clusters_options = [2, 3, 4, 5, 6]\n",
    "init_options = ['k-means++', 'random']\n",
    "best_score = -1\n",
    "best_params = {}\n",
    "\n",
    "for n_clusters in n_clusters_options:\n",
    "    print('==========')    \n",
    "    print(f'numero de clusters: {n_clusters}')\n",
    "    for init in init_options:\n",
    "        print(f'inicialização com: {init}')\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init=init, n_init=10, max_iter=300,  random_state=42)\n",
    "        for x in Xs:\n",
    "            print(f'dataset: {x}')\n",
    "            X = eval(x)\n",
    "            kmeans.fit(X)\n",
    "            labels = kmeans.labels_\n",
    "            score = silhouette_score(X, labels)\n",
    "            print(f'Score: {score} \\n')\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'n_clusters': n_clusters, 'init': init, 'tokenizador':x}\n",
    "\n",
    "print(f\"Melhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor pontuação de silhueta: {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f0c0c-ab0e-4ba7-84e9-dc5b7ba34f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6817137a-71cb-40de-8b3a-5beb08e92c3b",
   "metadata": {},
   "source": [
    "###### ======================= FIM DO TESTE =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e2904-5a54-4746-ab72-0a0abad1c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que você tenha um DataFrame chamado df\n",
    "\n",
    "# Ajustando opções de exibição do pandas para evitar truncamento\n",
    "pd.set_option('display.max_colwidth', None)  # Evita truncamento de coluna\n",
    "pd.set_option('display.max_rows', 15)  # Ajusta o número máximo de linhas a serem exibidas\n",
    "print(df['text'].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qm7SPTuZI6cG",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706112229865,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "Qm7SPTuZI6cG"
   },
   "outputs": [],
   "source": [
    "# Criando dataset para facilitar a geração de estatísticas dos resultados\n",
    "\n",
    "# sil_avg_df = pd.DataFrame(columns=['dataset', 'tokenizador', 'n_clusters', 'score'])\n",
    "sil_avg_df = pd.DataFrame(columns=['dataset', 'tokenizador','redutor', 'n_clusters', 'sil_score','inertia'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a1d96-309e-457e-bd29-9485f6106101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Imprimir a hora atual\n",
    "print('Inicio:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe888-448e-4775-b22a-46d4ffc8700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "n_init = 10\n",
    "max_iter = 300\n",
    "tol = 1e-4\n",
    "# metric = \"cosine\"  @# não é possível configura a métrica na biblioteca do sklearn, há uma otimiação interna \n",
    "init = \"k-means++\"\n",
    "weight  = None\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd3803-360c-4b0f-826d-04311bb132c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# início\n",
    "print('Inicio:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2879d7-28f3-4ee9-ae23-3fd41d04da7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69732,
     "status": "ok",
     "timestamp": 1706112299595,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "1cb9a95a-746d-4dce-9bdb-8b15df6e9a7c",
    "outputId": "c4e8bd41-e65f-4473-e5a7-dc56b9e907b6"
   },
   "outputs": [],
   "source": [
    "# Identificando o melhor valor de k\n",
    "# ajustar para 2 até 7 ou 9, reduzir o númeor de experimentos.\n",
    "# Adiciona os valores num dataframe para medição posterior\n",
    "range_n_clusters = range(2,10) #(2,20)\n",
    "# Definindo os parâmetros\n",
    "\n",
    "clbs_it = pd.DataFrame()\n",
    "# sil_avg_df = pd.DataFrame(columns=['dataset', 'tokenizador','redutor', 'n_clusters', 'score'])\n",
    "\n",
    "\n",
    "it = 0\n",
    "for num_clusters in range_n_clusters:\n",
    "    print('iteração:', it, ' : ',datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    it = it+1\n",
    "    km = KMeans(n_clusters=num_clusters, \n",
    "                init=init, \n",
    "                n_init=n_init, \n",
    "                max_iter=max_iter, \n",
    "                tol=tol, \n",
    "                random_state=random_state)\n",
    "    # km = KMeans(n_clusters=num_clusters, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "  \n",
    "\n",
    "    \n",
    "    # Com vetor TF-IDF:\n",
    "    # print('TF-IDF')\n",
    "    # SVD:\n",
    "    \n",
    "    df_xcluster_labels = km.fit_predict(svd_tfidf_sc)\n",
    "    lst2 = ['svd_tfidf_sc','tfidf','SVD',num_clusters,silhouette_score(svd_tfidf_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2\n",
    "    clbs_it['svd_tfidf_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "    \n",
    "    # UMAP:\n",
    "    df_xcluster_labels = km.fit_predict(umap_tfidf_sc)\n",
    "    lst2 = ['umap_tfidf_sc','tfidf','UMAP',num_clusters,silhouette_score(umap_tfidf_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2\n",
    "    clbs_it['umap_tfidf_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "\n",
    "    # t-SNE\n",
    "    df_xcluster_labels = km.fit_predict(tsne_tfidf_sc)\n",
    "    lst2 = ['tsne_tfidf_sc','tfidf','t-SNE',num_clusters,silhouette_score(tsne_tfidf_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2    \n",
    "    clbs_it['tsne_tfidf_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "\n",
    "    # NMF    :\n",
    "    df_xcluster_labels = km.fit_predict(nmf_tfidf_sc)\n",
    "    lst2 = ['nmf_tfidf_sc','tfidf','NMF',num_clusters,silhouette_score(nmf_tfidf_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2   \n",
    "    clbs_it['nmf_tfidf_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "\n",
    "\n",
    "\n",
    "    # Com vetor Word to Vector W2v:\n",
    "    # print('W2v')\n",
    "    # SVD:\n",
    "    df_xcluster_labels = km.fit_predict(svd_w2v_sc)\n",
    "    lst2 = ['svd_w2v_sc','W2v','SVD',num_clusters,silhouette_score(svd_w2v_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2\n",
    "    clbs_it['svd_w2v_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "    \n",
    "    # UMAP:\n",
    "    df_xcluster_labels = km.fit_predict(umap_w2v_sc)\n",
    "    lst2 = ['umap_w2v_sc','W2v','UMAP',num_clusters,silhouette_score(umap_w2v_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2\n",
    "    clbs_it['umap_w2v_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "\n",
    "    # t-SNE\n",
    "    df_xcluster_labels = km.fit_predict(tsne_w2v_sc)\n",
    "    lst2 = ['tsne_w2v_sc','W2v','t-SNE',num_clusters,silhouette_score(tsne_w2v_sc, df_xcluster_labels),km.inertia_]\n",
    "    sil_avg_df.loc[len(sil_avg_df)+1] = lst2   \n",
    "    clbs_it['tsne_w2v_sc-' +f'{num_clusters}'] = df_xcluster_labels \n",
    "\n",
    "    # NMF    : Não aplicável à W2v\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0c1d7-cb63-44f9-8903-8a95df070dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5bb81-1bd7-4159-914d-2f8b248b4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fim\n",
    "print('termino: ', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ace7b-af0d-4134-a12c-ebdc816cb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localizando o melhor valor para k\n",
    "n = np.argmax(sil_avg_df[['sil_score']])\n",
    "best_k = sil_avg_df.iloc[n]['n_clusters']\n",
    "sil_avg_df.iloc[n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e459aa-8e64-4931-a5c1-e8a9cabb384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_elbow_curve(data, k_range, n_init, title):\n",
    "  \"\"\"\n",
    "  Gera a curva de cotovelo para o algoritmo k-means.\n",
    "\n",
    "  Argumentos:\n",
    "    data: Matriz numpy com os dados.\n",
    "    k_range: Lista com os valores de k a serem testados.\n",
    "    n_init: Número de inicializações aleatórias dos centroides para cada valor de k.\n",
    "    title: Título do gráfico.\n",
    "\n",
    "  Retorna:\n",
    "    Tuple com:\n",
    "      - k_values: Lista com os valores de k.\n",
    "      - distortions: Lista com as distorções médias para cada valor de k.\n",
    "  \"\"\"\n",
    "\n",
    "  k_values = []\n",
    "  distortions = []\n",
    "  for k in k_range:\n",
    "    k_values.append(k)\n",
    "    \n",
    "    distortion_list = []\n",
    "    for _ in range(n_init):\n",
    "      kmeans = KMeans(n_clusters=k,n_init=10, random_state=np.random.randint(0, 100000))\n",
    "      kmeans.fit(data)\n",
    "      distortion_list.append(kmeans.inertia_)\n",
    "    \n",
    "    distortions.append(np.mean(distortion_list))\n",
    "\n",
    "  # Plotando a curva de cotovelo\n",
    "  plt.plot(k_values, distortions)\n",
    "  plt.xlabel(\"Número de clusters (k)\")\n",
    "  plt.ylabel(\"Distorção média\")\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "# # Definindo os datasets\n",
    "# svd_tfidf = ... # Insira o dataset svd_tfidf aqui\n",
    "# svd_W2v = ... # Insira o dataset svd_W2v aqui\n",
    "\n",
    "# Definindo os parâmetros\n",
    "k_range = list(range(2, 11))\n",
    "n_init = 10\n",
    "\n",
    "# # Gerando as curvas de cotovelo\n",
    "# kmeans_elbow_curve(svd_tfidf, k_range, n_init, \"Curva de cotovelo - SVD TF-IDF\")\n",
    "# kmeans_elbow_curve(svd_W2v, k_range, n_init, \"Curva de cotovelo - SVD Word2Vec\")\n",
    "\n",
    "# Adicionando mais datasets\n",
    "# ... Insira o código para adicionar mais datasets aqui ...\n",
    "\n",
    "# Função para plotar as curvas de cotovelo de vários datasets\n",
    "def plot_multiple_elbow_curves(data_dict, title):\n",
    "  \"\"\"\n",
    "  Plota as curvas de cotovelo para vários datasets.\n",
    "\n",
    "  Argumentos:\n",
    "    data_dict: Dicionário com os datasets. As chaves do dicionário devem ser strings com os nomes dos datasets e os valores devem ser matrizes numpy com os dados.\n",
    "    title: Título do gráfico.\n",
    "  \"\"\"\n",
    "\n",
    "  for name, data in data_dict.items():\n",
    "    kmeans_elbow_curve(data, k_range, n_init, name)\n",
    "  \n",
    "  plt.xlabel(\"Número de clusters (k)\")\n",
    "  plt.ylabel(\"Distorção média\")\n",
    "  plt.title(title)\n",
    "  name = f'{dataset}-{tokenizador}-{redutor}-elbow_sil_df2.png'\n",
    "  plt.savefig(name)  \n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14251c81-039a-4f54-9735-c94f7bb50a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotando as curvas de cotovelo dos datasets\n",
    "data_dict = {\n",
    "    \"SVD TF-IDF\": np.array(svd_tfidf),\n",
    "    \"UMAP TF-IDF\": umap_tfidf,\n",
    "    \"tSEN TF-IDF\": tsne_tfidf,\n",
    "    \"NMF TF-IDF\": nmf_tfidf,\n",
    "    \"SVD Word2Vec\": np.array(svd_w2v),\n",
    "    \"UMAP Word2Vec\": umap_w2v,\n",
    "    \"tSEN Word2Vec\": tsne_w2v\n",
    "    \n",
    "  # ... Insira outros datasets aqui ...\n",
    "}\n",
    "\n",
    "plot_multiple_elbow_curves(data_dict, \"Curvas de cotovelo - Múltiplos datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c50e2-7250-40aa-8bb4-2f792bcb4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotando a análise de silhueta dos datasets\n",
    "data_dict = {\n",
    "    \"UMAP TF-IDF\": umap_tfidf,\n",
    "    \"tSEN TF-IDF\": tsne_tfidf,\n",
    "    \"NMF TF-IDF\": nmf_tfidf,\n",
    "    \"SVD TF-IDF\": svd_tfidf,    \n",
    "    \"SVD Word2Vec\": svd_w2v,\n",
    "    \"UMAP Word2Vec\": umap_w2v,\n",
    "    \"tSEN Word2Vec\": tsne_w2v\n",
    "    \n",
    "  # ... Insira outros datasets aqui ...\n",
    "}\n",
    "\n",
    "# plot_multiple_silhouette_analysis(data_dict, \"Análise de Silhueta - Múltiplos datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d5695-6862-4955-a6be-a768c89480c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fim\n",
    "print('termino: ', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dcede-078b-495f-b429-c12d7f93722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Excluir possíveis duplicatas das combinações \n",
    "print(sil_avg_df.shape)\n",
    "combinacoes_unicas = sil_avg_df[['dataset', 'tokenizador', 'redutor']].drop_duplicates()\n",
    "print(combinacoes_unicas.shape)\n",
    "\n",
    "\n",
    "# Plotar gráficos para cada combinação\n",
    "for _, row in combinacoes_unicas.iterrows():\n",
    "    dataset = row['dataset']\n",
    "    tokenizador = row['tokenizador']\n",
    "    redutor = row['redutor']\n",
    "    \n",
    "    # Filtrar o DataFrame para a combinação atual\n",
    "    df_filtrado = sil_avg_df[(sil_avg_df['dataset'] == dataset) & (sil_avg_df['tokenizador'] == tokenizador) & (sil_avg_df['redutor'] == redutor)]\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.suptitle(f'Resultados para df2: {tokenizador} e {redutor}', fontsize=16, y=1.05)  # Ajuste o tamanho da fonte e a posição do título conforme necessário\n",
    "    \n",
    "\n",
    "    \n",
    "    # Plotar Silhouette Score\n",
    "\n",
    "    plt.subplot(1, 2, 1) # Subplot 1\n",
    "    plt.plot(df_filtrado['n_clusters'], df_filtrado['sil_score'], marker='o')\n",
    "    plt.title(f'Silhouette Score')#\\n{tokenizador}, {redutor}')\n",
    "    plt.xlabel('Número de Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plotar Inertia\n",
    "    plt.subplot(1, 2, 2) # Subplot 2\n",
    "    plt.plot(df_filtrado['n_clusters'], df_filtrado['inertia'], marker='o')\n",
    "    plt.title(f'Inertia')#\\n{tokenizador}, {redutor}')\n",
    "    plt.xlabel('Número de Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    name = f'df1_{tokenizador}-{redutor}-elbow_sil.png'\n",
    "    plt.savefig(name)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bc78d-4ed1-46fc-bd94-e88f63dc5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que sil_avg_df seja o DataFrame contendo os dados\n",
    "\n",
    "# Encontrar combinações únicas de 'dataset', 'tokenizador', 'redutor' para usar como categorias\n",
    "combinacoes = sil_avg_df[['dataset', 'tokenizador', 'redutor']].drop_duplicates()\n",
    "\n",
    "# Criar uma figura e um eixo para o plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Cores diferentes para cada combinação\n",
    "cores = plt.cm.tab20(np.linspace(0, 1, len(combinacoes)))\n",
    "\n",
    "for i, (index, row) in enumerate(combinacoes.iterrows()):\n",
    "    # Filtrar o DataFrame para a combinação atual\n",
    "    df_filtrado = sil_avg_df[(sil_avg_df['dataset'] == row['dataset']) & \n",
    "                             (sil_avg_df['tokenizador'] == row['tokenizador']) & \n",
    "                             (sil_avg_df['redutor'] == row['redutor'])]\n",
    "    \n",
    "    # Ordenar o DataFrame filtrado por 'n_clusters' para garantir a linha contínua\n",
    "    df_filtrado = df_filtrado.sort_values(by='n_clusters')\n",
    "    \n",
    "    # Plotar linha e pontos\n",
    "    ax.plot(df_filtrado['n_clusters'], df_filtrado['sil_score'], marker='o', linestyle='-', color=cores[i], label=f\"{row['dataset']}, {row['tokenizador']}, {row['redutor']}\")\n",
    "    \n",
    "# Ajustar detalhes do gráfico\n",
    "ax.set_xlabel('Número de Clusters')\n",
    "ax.set_ylabel('Silhouette Score')\n",
    "ax.set_title('Silhouette Scores por Número de Clusters para Diferentes Configurações')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.xticks(np.unique(sil_avg_df['n_clusters'])) # Garante que todos os números de clusters estejam nos ticks\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_silhueta_numClusters')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed22e40-4ffe-4ce0-961f-a5f64d84636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que sil_avg_df seja o DataFrame contendo os dados\n",
    "\n",
    "# Encontrar combinações únicas de 'dataset', 'tokenizador', 'redutor' para usar como categorias\n",
    "combinacoes = sil_avg_df[['dataset', 'tokenizador', 'redutor']].drop_duplicates()\n",
    "\n",
    "# Criar uma figura e um eixo para o plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Cores diferentes para cada combinação\n",
    "cores = plt.cm.tab20(np.linspace(0, 1, len(combinacoes)))\n",
    "\n",
    "for i, (index, row) in enumerate(combinacoes.iterrows()):\n",
    "    # Filtrar o DataFrame para a combinação atual\n",
    "    df_filtrado = sil_avg_df[(sil_avg_df['dataset'] == row['dataset']) & \n",
    "                             (sil_avg_df['tokenizador'] == row['tokenizador']) & \n",
    "                             (sil_avg_df['redutor'] == row['redutor'])]\n",
    "    \n",
    "    # Ordenar o DataFrame filtrado por 'n_clusters' para garantir a linha contínua\n",
    "    df_filtrado = df_filtrado.sort_values(by='n_clusters')\n",
    "    \n",
    "    # Plotar linha e pontos para a inércia\n",
    "    ax.plot(df_filtrado['n_clusters'], df_filtrado['inertia'], marker='o', linestyle='-', color=cores[i], label=f\"{row['dataset']}, {row['tokenizador']}, {row['redutor']}\")\n",
    "\n",
    "# Ajustar detalhes do gráfico\n",
    "ax.set_xlabel('Número de Clusters')\n",
    "ax.set_ylabel('Inércia')  # Alterar para Inércia\n",
    "ax.set_title('Método de Cotovelo: Inércia por Número de Clusters para Diferentes Configurações')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.xticks(np.unique(sil_avg_df['n_clusters'])) # Garante que todos os números de clusters estejam nos ticks\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/images/df1_cotovelo_numClusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29293dae-20e0-4e7b-a207-5e5c2cc58b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval(sil_avg_df['dataset'])\n",
    "clusters_unique = sil_avg_df['n_clusters'].unique()\n",
    "datasets_unique = sil_avg_df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefc066-cf41-4038-9540-9fc0596b327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que sil_avg_df seja o seu DataFrame com os dados de clusters e os rótulos de cluster correspondentes\n",
    "# E que você tenha seu conjunto de dados original X para calcular as amostras de silhueta\n",
    "\n",
    "# Escolher um esquema de cores para os gráficos\n",
    "cmap = cm.get_cmap(\"Spectral\")\n",
    "\n",
    "# Definindo o número de colunas por linha\n",
    "cols_per_row = 4\n",
    "\n",
    "# Estrutura para armazenar informações dos gráficos (incluindo a presença de valores negativos)\n",
    "plot_info = []\n",
    "\n",
    "for dataset in datasets_unique:\n",
    "    for n_clusters in clusters_unique:\n",
    "        # Assumindo que 'clbs_it' e 'dataset' sejam definidos anteriormente (ajuste conforme necessário)\n",
    "        cluster_labels = clbs_it[f'{dataset}-{n_clusters}']\n",
    "        X = eval(dataset)  # Use com cautela, certifique-se de que 'dataset' vem de uma fonte confiável\n",
    "        silhouette_vals = silhouette_samples(X, cluster_labels)\n",
    "        \n",
    "        # Verifica se existem valores negativos\n",
    "        has_negative_values = np.any(silhouette_vals < 0)\n",
    "        \n",
    "        # Armazenar informações para ordenação posterior\n",
    "        plot_info.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"silhouette_vals\": silhouette_vals,\n",
    "            \"cluster_labels\": cluster_labels,\n",
    "            \"has_negative_values\": has_negative_values\n",
    "        })\n",
    "\n",
    "# Ordenar os gráficos colocando aqueles sem valores negativos primeiro\n",
    "plot_info_sorted = sorted(plot_info, key=lambda x: x['has_negative_values'])\n",
    "\n",
    "# Calcular o número total de subplots\n",
    "total_plots = len(plot_info_sorted)\n",
    "\n",
    "# Calcular o número de linhas necessário, garantindo pelo menos uma linha\n",
    "num_rows = ((total_plots - 1) // cols_per_row) + 1\n",
    "\n",
    "# Ajustar o tamanho da figura para acomodar os subplots adequadamente\n",
    "fig_width = 14\n",
    "fig_height = num_rows * 4  # Ajuste a altura conforme necessário para evitar sobreposição\n",
    "plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "for i, info in enumerate(plot_info_sorted):\n",
    "    ax = plt.subplot(num_rows, cols_per_row, i + 1)\n",
    "    plt.subplots_adjust(bottom=0.1, top=0.9, hspace=0.4, wspace=0.4)\n",
    "\n",
    "    n_clusters = info[\"n_clusters\"]\n",
    "    silhouette_vals = info[\"silhouette_vals\"]\n",
    "    cluster_labels = info[\"cluster_labels\"]\n",
    "    sil_avg = silhouette_score(X, cluster_labels)\n",
    "    \n",
    "    y_lower = 10\n",
    "    for j in range(n_clusters):\n",
    "        jth_cluster_silhouette_vals = silhouette_vals[cluster_labels == j]\n",
    "        jth_cluster_silhouette_vals.sort()\n",
    "        \n",
    "        size_cluster_j = jth_cluster_silhouette_vals.shape[0]\n",
    "        y_upper = y_lower + size_cluster_j\n",
    "\n",
    "        color = cmap(float(j) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                         0, jth_cluster_silhouette_vals,\n",
    "                         facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        \n",
    "        y_lower = y_upper + 10  # 10 para o espaço entre silhuetas\n",
    "\n",
    "    ax.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax.set_yticks([])  # Limpar os yaxis labels / ticks\n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    ax.set_title(f\"{info['dataset']} | {n_clusters} clusters\", fontsize=10)\n",
    "    ax.set_xlabel('Silhouette coefficient values', fontsize=9)\n",
    "    ax.set_ylabel('Cluster', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AKi_zzbF_wTQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "executionInfo": {
     "elapsed": 1198,
     "status": "ok",
     "timestamp": 1706112300789,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "AKi_zzbF_wTQ",
    "outputId": "63b339e0-1071-4cb2-adc3-7ab2d923b593"
   },
   "outputs": [],
   "source": [
    "# Encontrar a entrada com o maior Silhouette Score\n",
    "melhor_silhouette = sil_avg_df.loc[sil_avg_df['sil_score'].idxmax()]\n",
    "print(f\"Melhor Silhouette Score: {melhor_silhouette['sil_score']} para {melhor_silhouette['n_clusters']} clusters, com tokenizador {melhor_silhouette['tokenizador']} e redutor {melhor_silhouette['redutor']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8Li-KuDP9RO",
   "metadata": {
    "id": "s8Li-KuDP9RO"
   },
   "source": [
    "##### 4. Treinamento do KMeans com o Texto Tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e23d7c-41c8-4ed4-ae22-341b102bdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed987774-3b70-489b-ba7d-e6facfeba470",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1706112300790,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "ed987774-3b70-489b-ba7d-e6facfeba470"
   },
   "outputs": [],
   "source": [
    "#treinando com os melhores parâmetros\n",
    "# best_xkdf\n",
    "n_clusters = 5\n",
    "km_df = KMeans(n_clusters=n_clusters ,init='k-means++', n_init=10, max_iter=500, random_state=42)\n",
    "# kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iD6Yz9PCcnZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1706112300790,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "4iD6Yz9PCcnZ",
    "outputId": "5a9d34ba-f403-4499-f8db-20f98ea471e2"
   },
   "outputs": [],
   "source": [
    "#Submetendo o Kmean aos parâmetros]\n",
    "#tfidf\n",
    "xcl_tf_svd = km_df.fit_predict( svd_tfidf_sc)#dfx_idf)\n",
    "xcl_tf_nmf = km_df.fit_predict( nmf_tfidf_sc)#dfx_idf)\n",
    "xcl_tf_umap = km_df.fit_predict(umap_tfidf_sc)#dfx_idf)\n",
    "xcl_tf_tsne = km_df.fit_predict(tsne_tfidf_sc)#dfx_idf)\n",
    "\n",
    "#W2v\n",
    "xcl_w2v_svd = km_df.fit_predict( svd_w2v_sc)#dfx_idf)\n",
    "xcl_w2v_umap = km_df.fit_predict(umap_w2v_sc)#dfx_idf)\n",
    "xcl_w2v_tsne = km_df.fit_predict(tsne_w2v_sc)#dfx_idf)\n",
    "# umap_w2v_sc,tsne_w2v_sc,svd_w2v_sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9f076-c45e-462e-920c-8ee9adccbac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(xcl_tf_svd,  xcl_tf_nmf,xcl_tf_umap,xcl_tf_tsne)\n",
    "df['xcl_tf_svd']=xcl_tf_svd\n",
    "df['xcl_tf_nmf']=xcl_tf_nmf\n",
    "df['xcl_tf_umap']=xcl_tf_umap\n",
    "df['xcl_tf_tsne']=xcl_tf_tsne\n",
    "\n",
    "df['xcl_w2v_svd']=xcl_tf_svd\n",
    "df['xcl_w2v_umap']=xcl_tf_nmf\n",
    "df['xcl_w2v_tsne']=xcl_tf_umap\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf35545-79f8-4b98-acc5-98a73edcd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['target','xcl_tf_svd','xcl_tf_nmf','xcl_tf_svd','xcl_tf_tsne','xcl_w2v_svd','xcl_w2v_umap','xcl_w2v_tsne']][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OEjcwGMOQAUa",
   "metadata": {
    "id": "OEjcwGMOQAUa"
   },
   "source": [
    "##### 5. Geração de Estatísticas e Mensuração dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823ed27-225f-40cd-b1c7-b252c90b1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste de geração de métricas e gráficos \n",
    "# 3 células:\n",
    "# 1º - função de cálculos das métricas\n",
    "# 2º - \n",
    "# 3º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10f063-7b40-4892-8a4c-e9a1690df8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update --all -y # já executado - 04/02/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555a865-8fef-4fce-a55c-c7319e6f34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -n base -c defaults conda -y # já executado 04/02/2024\n",
    "# !conda install conda=24.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d977c-ecab-4ebf-b5d8-6103c9262e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listas com resultados para gráficos\n",
    "Xs = ['tsne_tfidf_sc', 'svd_tfidf_sc','umap_tfidf_sc','nmf_tfidf_sc','tsne_w2v_sc','svd_w2v_sc','umap_w2v_sc']\n",
    "cl=  ['xcl_tf_tsne'  , 'xcl_tf_svd'  ,'xcl_tf_umap'  ,'xcl_tf_nmf'  ,'xcl_w2v_tsne','xcl_w2v_svd','xcl_w2v_umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a1b70-c15f-4d94-bc8f-0335ecf1fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score, v_measure_score, f1_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f677e90-dc73-42f7-ad71-9c8f98cf6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(Xs,cl):\n",
    "    data = eval(x)\n",
    "    labels = eval(y)\n",
    "    plot_(2,data,x,labels)\n",
    "    name = 'df1_' + x +' ' + str(n_clusters) + '.png'\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03ed31-65b4-421b-9afb-737fab861dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cols = ['xcl_tf_svd', 'xcl_tf_nmf', 'xcl_tf_svd', 'xcl_tf_tsne', 'xcl_w2v_svd', 'xcl_w2v_umap', 'xcl_w2v_tsne']\n",
    "metrics_df = calculate_metrics(df, 'target', cl) #predicted_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f3903-976a-4e63-b7dd-86c93a6c58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, target_col, predicted_cols):\n",
    "    metrics = {\n",
    "        'Model': [],\n",
    "        'ARI Score': [],\n",
    "        'V-measure Score': [],\n",
    "        'F1-Score': []\n",
    "    }\n",
    "    \n",
    "    for col in predicted_cols:\n",
    "        ari_score = adjusted_rand_score(df[target_col], df[col])\n",
    "        v_measure = v_measure_score(df[target_col], df[col])\n",
    "        \n",
    "        # Para o cálculo do F1-Score, precisamos de labels, então usaremos 'macro' para uma média não ponderada\n",
    "        # Como o F1-Score é calculado para classificação, precisamos converter para int se não forem\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(df[target_col].astype(int), df[col].astype(int), average='macro')\n",
    "        \n",
    "        metrics['Model'].append(col)\n",
    "        metrics['ARI Score'].append(ari_score)\n",
    "        metrics['V-measure Score'].append(v_measure)\n",
    "        metrics['F1-Score'].append(f1_score)\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d60641-82ee-440c-a9ae-e29357a7beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando compração entre as avaliações\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.barplot(x='ARI Score', y='Model', data=metrics_df, palette='viridis')\n",
    "sns.barplot(x='ARI Score', y='Model', hue='Model', data=metrics_df, palette='viridis', legend=False)\n",
    "plt.title('Comparação do ARI Score por Modelo')\n",
    "plt.title('Comparação do V-measure Score por Modelo')\n",
    "name = 'df1_ARIScore-'+ str(n_clusters) + 'cls.png'\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(x='V-measure Score', y='Model', hue='Model', data=metrics_df, palette='viridis', legend=False)\n",
    "plt.title('Comparação do V-measure Score por Modelo')\n",
    "name = 'df1_VMesure-'+ str(n_clusters) + 'cls.png'\n",
    "plt.savefig(name)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(x='F1-Score', y='Model', hue='Model', data=metrics_df, palette='viridis', legend=False)\n",
    "plt.title('Comparação do F1-Score por Modelo')\n",
    "name = 'df1_F1Score-'+ str(n_clusters) + '-cls.png'\n",
    "plt.savefig(name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c26c0-0473-4525-8892-ca47694a9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fim da geração de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cb74f-bb21-4067-a4ff-271c60f9d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x,y in zip(Xs,cl):\n",
    "    data = eval(x)\n",
    "    labels = eval(y)\n",
    "    plot_(2,data,x,labels)\n",
    "    name = 'df2_' + x + str(n_clusters) + '-cls.png'\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f133e00-fdc4-4d3d-ab99-f406587907d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gráfico de dispersão dos resultados\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "\n",
    "# for x,y in zip(Xs,cl):\n",
    "#     data = eval(x)\n",
    "#     labels = eval(y)\n",
    "# # Crie um gráfico de dispersão\n",
    "#     fig = px.scatter(data, x=data[:, 0], y=data[:, 1], color=labels)\n",
    "#     fig.update_traces(marker=dict(size=3)) \n",
    "    \n",
    "#     # Adicione um título ao gráfico\n",
    "#     fig.update_layout(title='K-means clustering' + \" - \" + x)\n",
    "    \n",
    "#     # Adicione rótulos aos eixos x e y\n",
    "#     fig.update_xaxes(title='Feature 1')\n",
    "#     fig.update_yaxes(title='Feature 2')\n",
    "    \n",
    "#     # Mostre o gráfico\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964887e-5850-432f-a4e2-daa234575515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que 'Xs' e 'cl' sejam listas de strings com os nomes das variáveis\n",
    "# Exemplo:\n",
    "# Xs = ['svd_w2v_sc_1', 'svd_w2v_sc_2']\n",
    "# cl = ['labels_1', 'labels_2']\n",
    "\n",
    "for x, y in zip(Xs, cl):\n",
    "    data = eval(x)\n",
    "    labels = eval(y)\n",
    "    \n",
    "    # Crie um gráfico de dispersão\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Obter os rótulos únicos para colorir os pontos\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        # Filtrar pontos por rótulo\n",
    "        ix = np.where(labels == label)\n",
    "        plt.scatter(data[ix, 0], data[ix, 1], label=f'Cluster {label}', s=2)  # s controla o tamanho do ponto\n",
    "    \n",
    "    # Adicione um título ao gráfico\n",
    "    plt.title(f'K-means clustering - {x}')\n",
    "    \n",
    "    # Adicione rótulos aos eixos x e y\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    \n",
    "    # Adicionar legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    # Mostrar o gráfico\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b55eab-cea5-4293-98e5-3fd1e98a8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "metrics = {}\n",
    "# cluster_ = ['xcl_tf_tsne', 'xcl_tf_svd', 'xcl_tf_nmf', 'xcl_tf_umap']\n",
    "cluster_ = ['xcl_tf_tsne'  \n",
    "            ,'xcl_tf_svd'  \n",
    "            ,'xcl_tf_nmf'  \n",
    "            ,'xcl_tf_umap' \n",
    "            ,'xcl_w2v_svd' \n",
    "            ,'xcl_w2v_umap'\n",
    "            ,'xcl_w2v_tsne']\n",
    "# Calcula métricas para cada conjunto de clusters\n",
    "for c in cluster_:\n",
    "    print('*==================================*')\n",
    "    cluster_col = f'{c}'\n",
    "    print(f'cluster_col: {cluster_col}')\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(df['target'], df[cluster_col])\n",
    "    print(f\"Matriz de confusão para {cluster_col}:\\n\", cm)\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    report = classification_report(df['target'], df[cluster_col], output_dict=True)\n",
    "    print(f\"Relatório de classificação para {cluster_col}:\\n\", report)\n",
    "    \n",
    "    # Calcula a pontuação de silhueta\n",
    "    silhouette_avg = silhouette_score(df.drop(['text','subject','txt_limpo','txt_lmtzd','target', 'xcl_tf_tsne', 'xcl_tf_svd', 'xcl_tf_nmf', 'xcl_tf_umap'], axis=1), df[cluster_col])\n",
    "     # silhouette_avg = silhouette_score(df.drop(['target', 'subject', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4'], axis=1), df[cluster_col])\n",
    "    print(f\"Pontuação de silhueta para {cluster_col}: {silhouette_avg}\\n\")\n",
    "    \n",
    "    metrics[cluster_col] = {\n",
    "        'silhouette_score': silhouette_avg,\n",
    "        **report['weighted avg']\n",
    "    }\n",
    "\n",
    "# Comparando os resultados\n",
    "for cluster_col, metric in metrics.items():\n",
    "    print(f\"\\n{cluster_col}: Silhouette Score = {metric['silhouette_score']}, \\nPrecision = {metric['precision']}, \\nRecall = {metric['recall']}, \\nF1-Score = {metric['f1-score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M78Vm5Y1RjId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "M78Vm5Y1RjId",
    "outputId": "7df6c961-255f-4855-a668-77451ecffcc9"
   },
   "outputs": [],
   "source": [
    "\n",
    "#com Word2Vec - Lista\n",
    "# 'nmf_tfidf_sc','svd_tfidf_sc','tsne_tfidf_sc','umap_tfidf_sc','svd_w2v_sc','tsne_w2v_sc','umap_w2v_sc'\n",
    "df_xcl_tf = km_df.fit_predict(nmf_tfidf_sc)#xdf_W2V)\n",
    "df_xcl_w2v = km_df.fit_predict(svd_w2v_sc)#xdf_W2V)\n",
    "# df_lcluster_labels_W2V = km_df.fit_predict(kmW2V_ldf)\n",
    "\n",
    "# antes de executar novamente, transformar a lista de 44898 elementos, cada um é uma np.array de 200 itens.\n",
    "# preciso transformar ou num arrau de 44898 x 200 ou num dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R98jbG0HvLSP",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "R98jbG0HvLSP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yb_BgG6RQDwJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "Yb_BgG6RQDwJ",
    "outputId": "81383a5e-3a5f-4020-ec71-652c48d85694"
   },
   "outputs": [],
   "source": [
    "cluster_labels = km_df.labels_\n",
    "# Aqui você pode calcular ARI, Silhouette Score etc., como mencionado anteriormente\n",
    "# print(len(nmf_tfidf_sc), '\\n', np.unique(cluster_labels) ,'\\n' , df_xcluster_labels ) #df1_xcluster_labels não pode se usado, foi iterado com 20 ciclos\n",
    "print(len(svd_w2v_sc), '\\n', np.unique(cluster_labels) ,'\\n' , df_xcluster_labels )\n",
    "\n",
    "#kmW2V_xdf1 valor inicialmente usado,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CR9ttZqw3a_8",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "CR9ttZqw3a_8"
   },
   "outputs": [],
   "source": [
    "clbs_it[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JXkl62hWvZef",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "JXkl62hWvZef"
   },
   "outputs": [],
   "source": [
    "matrizes = {\n",
    "    \"df_xcl_itf\": df_xcl_tf,\n",
    "    \"df_xcl_W2V\": df_xcl_w2v\n",
    "}\n",
    "\n",
    "# Obtendo os três primeiros caracteres de cada chave (nome da variável)\n",
    "primeiros_tres_caracteres = [nome[:2] for nome in matrizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb021bd-2b5a-4d98-b6ad-094f732cdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nmjqi3Pc6znh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706112302041,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "Nmjqi3Pc6znh",
    "outputId": "419aae27-9b8c-4fbb-86b3-887e7acaf4c6"
   },
   "outputs": [],
   "source": [
    "#filtrar as labels do kmeans para fazer a medição\n",
    "metricas=[]\n",
    "\n",
    "\n",
    "for nome,labels in matrizes.items():\n",
    "  name=(nome[:3]+ nome[-3:])\n",
    "  labels = labels\n",
    "  y = globals()[ 'y_' + nome[:2]]\n",
    "  metricas.append(coleta_metricas(y,labels,name))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u8QZM3JKIMVn",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706112302042,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "u8QZM3JKIMVn"
   },
   "outputs": [],
   "source": [
    "df_metricas =  pd.DataFrame(metricas)\n",
    "df_metricas.rename(columns={0:'dataset',1:'metrica',2:'score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KBAR0jPWKRIa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706112302042,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "KBAR0jPWKRIa",
    "outputId": "e62c37f9-4578-4b90-d914-391511568e57"
   },
   "outputs": [],
   "source": [
    "df_metricas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ICvpVy_VIUjL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1706112302509,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "ICvpVy_VIUjL",
    "outputId": "6b0d344d-b0bb-4ede-a992-c22d0f20fde5"
   },
   "outputs": [],
   "source": [
    "df_metricas.groupby(['dataset','metrica']).max(['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aQcLsRd7uniP",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706112302509,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "aQcLsRd7uniP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encontrar o array com o maior score\n",
    "metricas = [array for array in metricas if array and array[2] is not None]\n",
    "max_array = max(metricas, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AWHK7zKWIZmM",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706112302509,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "AWHK7zKWIZmM",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Exibir os resultados:\n",
    "# meu dicionário tem dataset, metrica, score da métrica\n",
    "# minhas métricas estão numa lista com todos os dataset trabalhados com td-idf e w2v.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQDoRFgE0O1_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706112302509,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "FQDoRFgE0O1_",
    "outputId": "d22b30ed-9206-444f-ebe4-4338e01588be"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, f1_score, precision_score, recall_score, homogeneity_completeness_v_measure\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que df_cluster_labels e y_df são seus clusters e rótulos para o primeiro conjunto de dados\n",
    "# Para o Índice Rand Ajustado\n",
    "ari_score_xdf = adjusted_rand_score(y_df, df_xcluster_labels)\n",
    "\n",
    "# Para V-measure\n",
    "homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(y_df, df_xcluster_labels)\n",
    "\n",
    "# Para F1-Score, Precisão e Revocação (necessário adaptar para multi-classe se for o caso)\n",
    "# Supondo que os rótulos e clusters estão alinhados (caso contrário, será necessário alinhá-los)\n",
    "precision_df = precision_score(y_df, df_xcluster_labels, average='macro')\n",
    "recall_df = recall_score(y_df, df_xcluster_labels, average='macro')\n",
    "f1_score_df = f1_score(y_df, df_xcluster_labels, average='macro')\n",
    "\n",
    "# Repita o processo para df_cluster_labels e y_df\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(\"ARI Score df:\", ari_score_xdf)\n",
    "print(\"Homogeneity df:\", homogeneity)\n",
    "print(\"Completeness df:\", completeness)\n",
    "print(\"V-measure df:\", v_measure)\n",
    "print(\"Precision df:\", precision_df)\n",
    "print(\"Recall df:\", recall_df)\n",
    "print(\"F1 Score df:\", f1_score_df)\n",
    "\n",
    "# Repita a impressão para o segundo conjunto de dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ligy4XvQEwW",
   "metadata": {
    "id": "0ligy4XvQEwW"
   },
   "source": [
    "6. Visualizações, Incluindo Visualizações Gráficas dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5821527-36e4-4876-b7b4-4dc3179ce0ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706112302509,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "e5821527-36e4-4876-b7b4-4dc3179ce0ef"
   },
   "outputs": [],
   "source": [
    "# #Aplicação do tSNE -\n",
    "# # ainda não testado\n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Suponha que df['text_alg1'] e df['text_alg2'] sejam suas colunas de texto tratadas\n",
    "# tfidf_mtx_ldf\n",
    "\n",
    "# Aplicando t-SNE\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# tsne_res_alg2 = tsne.fit_transform(dfx_idf.toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sa06UlP8yUCB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1706112410003,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "sa06UlP8yUCB",
    "outputId": "2e473e91-f76f-4bad-fe0a-e68fba12cd74"
   },
   "outputs": [],
   "source": [
    "# Visualização t-SNE em 3 dimensões\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "# tsne = TSNE(n_components=3, random_state=42)\n",
    "# tsne_res_alg2 = tsne.fit_transform(dfx_idf.toarray())\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "# # plt.subplot(1, 2, 2)\n",
    "# # plt.scatter(tsne_res_alg2[:, 0], tsne_res_alg2[:, 1], alpha=0.5)\n",
    "# # plt.title('Tratamento - df')\n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(tsne_res_alg2[:, 0], tsne_res_alg2[:, 1], tsne_res_alg2[:, 2], c=y)\n",
    "\n",
    "# ax.set_title('t-SNE 3D')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41XoivsyjzxT",
   "metadata": {
    "editable": true,
    "id": "41XoivsyjzxT",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Aplicando Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c13dce-95f2-45bd-9401-043f581f99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuração dos Parâmetros\n",
    "n_clusters = 4\n",
    "distance_metric = \"cosine\" #  euclidean\n",
    "n_init = 0\n",
    "max_iter = 300\n",
    "# df1\n",
    "# gerador de vetores: Word to Vector w2v\n",
    "# seleção de atributos: t-SNE\n",
    "# df: tsne_w2v_sc\n",
    "# método de escolha: cotovelo\n",
    "\n",
    "\n",
    "# df2\n",
    "# gerador de vetores: TF-IDF\n",
    "# seleção de atributos: t-SNE\n",
    "# df: tsne_tfidf_sc\n",
    "# método de escolha: cotovelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yz9eeBgEAczp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1706112410457,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "Yz9eeBgEAczp",
    "outputId": "17542a90-4fd8-403c-b2a2-07a37a70b834"
   },
   "outputs": [],
   "source": [
    "# Aplicação do k-means\n",
    "# Configurando o modelo\n",
    "n_clusters = 4\n",
    "km_xdf = KMeans(n_clusters=n_clusters, \n",
    "                n_init='auto', \n",
    "                random_state=42, \n",
    "                max_iter = max_iter).fit(svd_tfidf_sc)\n",
    "                # Preprocessing=True).fit(tsne_w2v_sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f12d6-5ebd-4716-a2cf-1ef1e2e76903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar os rótulos dos clusters ao DataFrame\n",
    "df['cluster_x'] = km_xdf.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c0d35-dc29-4de7-9460-f6e1282380d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df[df['cluster_x']==1][['text','target']].value_counts()\n",
    "df[df['cluster_x']==1][['target']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H2wRHPg8CUDR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1706112410781,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "H2wRHPg8CUDR",
    "outputId": "ffc70885-353c-41f8-c51b-dfe83742150f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verificações\n",
    "df[['subject','target','cluster_x']]\n",
    "a = df.groupby(['subject','cluster_x'])['target'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d51968-197f-40cc-a2be-aca8bb072c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reset_index(drop=False)\n",
    "# b['subject','cluster_x'] = a.redrop=False)[['subject','cluster_x']]\n",
    "# df['index'] = df.reset_index(drop=False)['index']\n",
    "set_index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9f4b0-ad19-4331-8d34-c07544e1633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[b['subject']=='worldnews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ca4a2-6e2a-4794-a0cb-c554dc8e9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "clbs_it.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35daa2-c2b7-4767-a85c-149e40a6c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação do k-means\n",
    "# Configurando o modelo\n",
    "n_clusters = 2\n",
    "km_xdf = KMeans(n_clusters=n_clusters, \n",
    "                n_init=10, \n",
    "                random_state=42, \n",
    "                max_iter = max_iter).fit(tsne_w2v_sc)\n",
    "                # Preprocessing=True).fit(tsne_w2v_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709e51a-b32e-457d-84a0-a70b39d33ec9",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1706112410781,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "7e5b632e-e520-485f-aaef-9be79100ca22",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Cálculo das métricas e visualização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5bfb3-1de7-48aa-a80b-f5aab341a9db",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1706112410781,
     "user": {
      "displayName": "Ivaneide Luccio",
      "userId": "06489097198794424524"
     },
     "user_tz": 180
    },
    "id": "f7c5bfb3-1de7-48aa-a80b-f5aab341a9db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, v_measure_score, adjusted_rand_score\n",
    "\n",
    "# Definindo os rótulos reais e os grupos do KMeans\n",
    "y_true = df['target']\n",
    "y_pred = km_xdf.labels_\n",
    "\n",
    "# Calculando as métricas\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "v_measure = v_measure_score(y_true, y_pred)\n",
    "ari = adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(f\"F1-score: {f1:.3f}\")\n",
    "print(f\"V-measure: {v_measure:.3f}\")\n",
    "print(f\"ARI: {ari:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358194bb-817a-4ec5-8e3a-9064dda8336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando as métricas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(['F1-score', 'V-measure', 'ARI'], [f1, v_measure, ari])\n",
    "plt.xlabel('Métrica')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Métricas de Agrupamento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6be90d-7f82-403f-921f-afebab3f472f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definindo as cores dos grupos\n",
    "# colors = ['r', 'g', 'b', 'c', 'm']\n",
    "colors = ['r', 'g', 'b', 'c', 'm']\n",
    "\n",
    "# Plotando os pontos\n",
    "plt.scatter(svd_tfidf_sc[:, 0], svd_tfidf_sc[:, 1],  c=df['cluster_x'], s=3)\n",
    "# color=colors[df['cluster_x']])\n",
    " # color=colors[df['kmeans_group'][i]]\n",
    "\n",
    "# Adicionando título e rótulos aos eixos\n",
    "plt.title('Gráfico de Dispersão - Agrupamentos KMeans')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Mostrando o gráfico\n",
    "plt.savefig('df1_x_cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e555a4-5631-4b6a-bcb8-86f6e8800dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b3a99-2732-4525-a504-3a33cf1f3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f900ab-2b35-4d52-bd9d-6426e5e0192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def sample_texts_by_cluster(df, sample_size, n_chars, filter_column):\n",
    "    # Identificar todos os clusters únicos na coluna\n",
    "    clusters = df[filter_column].unique()\n",
    "    \n",
    "    # Preparar um DataFrame para guardar as amostras de todos os clusters\n",
    "    samples_df = pd.DataFrame()\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        # Filtrar o DataFrame pelo cluster atual\n",
    "        filtered_df = df[df[filter_column] == cluster]\n",
    "        \n",
    "        # Coletar uma amostra aleatória\n",
    "        sample_df = filtered_df.sample(n=sample_size)\n",
    "        \n",
    "        # Reduzir o tamanho do texto\n",
    "        sample_df['text'] = sample_df['text'].apply(lambda x: x[:n_chars] if len(x) > n_chars else x)\n",
    "        \n",
    "        # Adicionar uma coluna indicando o valor do cluster da amostra\n",
    "        sample_df['cluster'] = cluster\n",
    "        \n",
    "        # Selecionar apenas as colunas de interesse e a coluna do cluster\n",
    "        sample_df = sample_df[['text', 'subject', 'target', 'cluster']]\n",
    "        \n",
    "        # Adicionar a amostra ao DataFrame de amostras\n",
    "        samples_df = pd.concat([sample_df,samples_df])\n",
    "    \n",
    "    return samples_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def sample_texts_by_attribute(df, attribute_value, sample_size, n_chars, filter_column):\n",
    "#     # Filtrar o DataFrame pelo valor do atributo na coluna especificada\n",
    "#     filtered_df = df[df[filter_column] == attribute_value]\n",
    "    \n",
    "#     # Coletar uma amostra aleatória\n",
    "#     sample_df = filtered_df.sample(n=sample_size)\n",
    "    \n",
    "#     # Reduzir o tamanho do texto\n",
    "#     sample_df['text'] = sample_df['text'].apply(lambda x: x[:n_chars] if len(x) > n_chars else x)\n",
    "    \n",
    "#     # Selecionar colunas específicas (assumindo 'target_o' como 'target')\n",
    "#     sample_df = sample_df[['text', 'subject', 'target',eval(filter_column)]]\n",
    "    \n",
    "#     return sample_df\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Supondo que seu DataFrame seja df\n",
    "# y_value = 1 (ou qualquer valor de 'y' que você deseja filtrar)\n",
    "# sample_size = 5 (número de amostras desejadas)\n",
    "# n_chars = 100 (número de caracteres por texto)\n",
    "\n",
    "# sample_df = sample_texts_by_y(df, y_value=1, sample_size=5, n_chars=100)\n",
    "# print(sample_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30120328-74ff-40b1-9846-00fa3e4b7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Supondo que você tenha um DataFrame chamado df\n",
    "# E que 'text' seja uma coluna de textos e 'cl_1', 'cl_2', 'cl_3', 'cl_4' sejam as colunas dos resultados dos clusters\n",
    "\n",
    "# Calculando métricas para cada coluna de agrupamento\n",
    "for X,y in zip(Xs,cl): # Isso itera de 1 a 4\n",
    "    cluster_col = y # Nome da coluna de agrupamento atual\n",
    "    \n",
    "    # Calcula as métricas para a coluna atual\n",
    "    silhouette_avg = silhouette_score(eval(X), df[cluster_col])\n",
    "    davies_bouldin_avg = davies_bouldin_score(eval(X), df[cluster_col])\n",
    "    calinski_harabasz_avg = calinski_harabasz_score(eval(X), df[cluster_col])\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print(f\"Métricas para {cluster_col}:\")\n",
    "    print(f\"  Silhouette Score: {silhouette_avg}\")\n",
    "    print(f\"  Davies-Bouldin Score: {davies_bouldin_avg}\")\n",
    "    print(f\"  Calinski-Harabasz Index: {calinski_harabasz_avg}\")\n",
    "    print(\"\")  # Linha em branco para separar os resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810b93e-414d-4d58-8ab1-dd7bac1bcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def totalize_by_attributes(df, attributes_to_filter):\n",
    "    # Dicionário para armazenar os resultados\n",
    "    results = {}\n",
    "    \n",
    "    for attr in attributes_to_filter:\n",
    "        # Agrupar por 'target' e 'subject' dentro de cada valor único de 'attributes_to_filter'\n",
    "        grouped = df.groupby([attr, 'target', 'subject']).size().reset_index(name='count')\n",
    "        \n",
    "        # Adicionar o resultado ao dicionário\n",
    "        results[attr] = grouped\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Lista de colunas que representam diferentes 'y'\n",
    "attributes_to_filter = ['y1', 'y2', 'y3']  # Substitua pelos nomes reais das colunas\n",
    "\n",
    "# Exemplo de uso:\n",
    "results = totalize_by_attributes(df,  cl)\n",
    "\n",
    "# Imprimir os resultados\n",
    "for attr, result in results.items():\n",
    "    print(f\"Totalização para {attr}:\")\n",
    "    print(result)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c9ecd-e37a-480c-84ae-d8b854d66df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos para substituir 'y'\n",
    "attributes_to_filter = cl\n",
    "\n",
    "# Valores para o exemplo\n",
    "sample_size = 10\n",
    "n_chars = 150\n",
    "\n",
    "for attr in attributes_to_filter:\n",
    "    print(f\"Amostras para a coluna {attr} e seus clusters:\")\n",
    "    samples_df = sample_texts_by_cluster(df, sample_size, n_chars, attr)\n",
    "    print(samples_df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850339a9-4e1c-4225-9670-cdbce6dacb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_by_cluster_attributes(df, cluster_columns):\n",
    "    # Criar um DataFrame vazio para armazenar os resultados\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    for column in cluster_columns:\n",
    "        # Para cada coluna de cluster, calcular a contagem de 'target' e 'subject'\n",
    "        counts = df.groupby([column, 'target', 'subject']).size().reset_index(name='count')\n",
    "        \n",
    "        # Renomear a coluna do cluster para 'cluster' para unificar os DataFrames de saída\n",
    "        counts.rename(columns={column: 'cluster'}, inplace=True)\n",
    "        \n",
    "        # Incluir a coluna identificando a qual 'y' (coluna de cluster) este resultado pertence\n",
    "        counts['cluster_attribute'] = column\n",
    "        \n",
    "        # Concatenar os resultados com o DataFrame de resultados\n",
    "        results_df = pd.concat([results_df, counts], ignore_index=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Lista de colunas que representam diferentes 'y' (clusters)\n",
    "cluster_columns = ['y1', 'y2', 'y3']  # Substitua pelos nomes reais das suas colunas de clusters\n",
    "\n",
    "# Chamada da função e impressão dos resultados\n",
    "results_df = count_by_cluster_attributes(df, cl)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a187624-e569-422e-8790-ba9e2ae181d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_cluster_counts(results_df):\n",
    "    # Configurações para melhorar a estética do gráfico\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Criando o gráfico\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Usar seaborn para criar um gráfico de barras com categorias aninhadas\n",
    "    sns.barplot(data=results_df, x='cluster_attribute', y='count', hue='subject', errorbar=None, palette='muted')\n",
    "    \n",
    "    plt.title('Contagem de Target e Subject por Cluster')\n",
    "    plt.xlabel('Cluster (Y)')\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Subject', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    plt.tight_layout()\n",
    "    name='df1_distribuicao_clusters.png'\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "# Chamando a função de plotagem com o DataFrame de resultados\n",
    "plot_cluster_counts(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200cf60-5795-462a-adae-f78cc1944ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cluster_proportions(results_df):\n",
    "    cluster_attributes = results_df['cluster_attribute'].unique()\n",
    "    \n",
    "    for cluster_attr in cluster_attributes:\n",
    "        # Filtrar os dados para o cluster_attribute atual\n",
    "        df_filtered = results_df[results_df['cluster_attribute'] == cluster_attr]\n",
    "        \n",
    "        # Calcular as proporções\n",
    "        total_count = df_filtered['count'].sum()\n",
    "        df_filtered['proportion'] = df_filtered['count'] / total_count\n",
    "        \n",
    "        # Preparar os dados para o gráfico\n",
    "        labels = df_filtered['subject']# + ' (' + str(df_filtered['target']) + ')'\n",
    "        sizes = df_filtered['proportion']\n",
    "        colors = plt.cm.tab20c(np.linspace(0, 1, len(labels)))\n",
    "        \n",
    "        # Criar gráfico de pizza\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "        plt.axis('equal')  # Para o gráfico ser circular\n",
    "        plt.title(f'Proporções de Subject e Target no Cluster {cluster_attr}')\n",
    "        plt.show()\n",
    "\n",
    "# Chamando a função com o DataFrame de resultados\n",
    "# plot_cluster_proportions(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d3222-6eb9-4cf9-a68f-c1f95994b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Suponha que df seja o seu DataFrame original\n",
    "\n",
    "# Primeiro, vamos remodelar o DataFrame para que cada linha represente uma amostra única,\n",
    "# com uma coluna para o 'y' (cluster_attribute), 'cluster', 'subject', e 'target'\n",
    "# Isso pode requerer transformar o DataFrame de um formato largo para um formato longo\n",
    "\n",
    "# Exemplo de como seu DataFrame pode ser transformado (isso é hipotético, adapte conforme necessário):\n",
    "df_long = pd.melt(df, id_vars=['subject', 'target'], var_name='y', value_name='cluster')\n",
    "\n",
    "# Agora, vamos calcular a contagem de cada combinação de 'y', 'cluster', 'subject', e 'target'\n",
    "df_count = df_long.groupby(['y', 'cluster', 'subject', 'target']).size().reset_index(name='count')\n",
    "\n",
    "# Calcular o total de amostras para cada 'y' para normalizar os dados e mostrar proporções\n",
    "df_count['total'] = df_count.groupby('y')['count'].transform('sum')\n",
    "df_count['proportion'] = df_count['count'] / df_count['total']\n",
    "\n",
    "# Plotar o gráfico\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=df_count, x='y', y='proportion', hue='cluster', errorbar=None, palette='muted', dodge=True)\n",
    "\n",
    "plt.title('Distribuição por Cluster dentro de Cada Y')\n",
    "plt.xlabel('Y')\n",
    "plt.ylabel('Proporção')\n",
    "plt.legend(title='Cluster')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876fba9-79b2-4a5c-a051-e917ee5aaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_cluster_bars(results_df):\n",
    "    # Calcular proporções\n",
    "    results_df['total'] = results_df.groupby('cluster_attribute')['count'].transform('sum')\n",
    "    results_df['proportion'] = results_df['count']# / results_df['total']\n",
    "    \n",
    "    # Configurar o tamanho e estilo do gráfico\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Criar o gráfico de barras agrupadas\n",
    "    sns.barplot(x=\"cluster_attribute\", y=\"proportion\", hue=\"subject\", data=results_df, palette=\"muted\", errorbar=None)\n",
    "    \n",
    "    plt.title('Proporções de Subject por Cluster Attribute')\n",
    "    plt.xlabel('Cluster Attribute')\n",
    "    plt.ylabel('Proporção')\n",
    "    plt.legend(title='Subject', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Mostrar o gráfico\n",
    "    plt.tight_layout()\n",
    "    name='df1_distribuicao_clusters.png'\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "# Chamando a função com o DataFrame de resultados\n",
    "plot_cluster_bars(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ff3e0-29a9-415a-99cf-b73de4e691ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos para substituir 'y'\n",
    "attributes_to_filter = cl\n",
    "\n",
    "# Valores para o exemplo\n",
    "sample_size = 10\n",
    "n_chars = 100\n",
    "attribute_value = 3 # Valor específico para filtragem, ajuste conforme necessário\n",
    "\n",
    "# Exemplo de uso com loop for\n",
    "for attr in attributes_to_filter:\n",
    "    for q in df[attr].unique():\n",
    "        print(f\"Amostras para {attr},  {q} clusters:\")\n",
    "        sample_df = sample_texts_by_attribute(df, attribute_value, sample_size, n_chars, eval(attr))\n",
    "        print(sample_df)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1d894-ae82-447d-a51e-5dbb4eea40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "41XoivsyjzxT"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
